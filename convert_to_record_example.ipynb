{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Refactored from Daniil's blog: TFRecords Guide\n",
    "# http://warmspringwinds.github.io/tensorflow/tf-slim/2016/12/21/tfrecords-guide/\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "from scipy.misc import imread, imresize\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "\n",
    "FLAGS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def convert_to(data_set, name):\n",
    "    \"\"\"Converts a dataset to tfrecords.\"\"\"\n",
    "    images = data_set.images\n",
    "    labels = data_set.labels\n",
    "    num_examples = data_set.num_examples\n",
    "    \n",
    "    if images.shape[0] != num_examples:\n",
    "        raise ValueError('Images size %d does not match label size %d.' %\n",
    "                        (images.shape[0], num_examples))\n",
    "    rows = images.shape[0]\n",
    "    cols = images.shape[2]\n",
    "    depth = images.shape[3]\n",
    "    \n",
    "    filename = os.path.join(FLAGS.directory, name + '.tfrecords')\n",
    "    print('Writing', filename)\n",
    "    writer = tf.python_io.TFRecordWriter(filename)\n",
    "    for index in range(num_examples):\n",
    "        image_str = images[index].tostring()\n",
    "        example = tf.train.Example(features=tf.train.Features(feature={\n",
    "            'height': _int64_feature(rows),\n",
    "            'width': _int64_feature(cols),\n",
    "            'depth': _int64_feature(depth),\n",
    "            'label': _int64_feature(int(labels[index])),\n",
    "            'image_raw': _bytess_feature(image_raw)\n",
    "        }))\n",
    "        writer.write(example.SerializeToString())\n",
    "    writer.close()\n",
    "    \n",
    "def main(_):\n",
    "    # Load Custom Dat (Caltech101)\n",
    "    cwd = os.getcwd()\n",
    "    path = os.path.join(cwd, FLAGS.directory)\n",
    "    valid_exts = ['.jpg', '.gif', '.png', '.jpeg']\n",
    "    print('%d categories in %s' % (len(os.listdir(path)), path))\n",
    "    \n",
    "    categories = sorted(os.listdir(path))\n",
    "    num_categ = len(categories)\n",
    "    \n",
    "    imgnames = []\n",
    "    labels = []\n",
    "    for label, category in enumerate(categories):\n",
    "        filelist = os.listdir(os.path.join(path, category))\n",
    "        imglist = []\n",
    "        for f in filelist:\n",
    "            ext = os.path.splitext(f)[-1]\n",
    "            if ext.lower() not in valid_exts:\n",
    "                continue\n",
    "            imglist.append(f)\n",
    "        imgnames += imglist\n",
    "        labels += [label]*len(imglist)\n",
    "        print('[%3d/%3d] %d %s images are found' % (label+1, num_categ,\n",
    "                                                    len(imglist), category))\n",
    "\n",
    "    numfiles = len(labels)\n",
    "    ratio = FLAGS.trainset_ratio\n",
    "    idxrand = np.random.permutation(numfiles)\n",
    "    idxtrain = idxrand[:int(ratio*numfiles)]\n",
    "    idxtest = idxrand[int(ratio*numfiles):]\n",
    "    \n",
    "    tfrecord_fname_train = 'custom_train.tfrecords'\n",
    "    tfrecord_fname_test = 'custom_test.tfrecords'\n",
    "    \n",
    "    writer_train = tf.python_io.TFRecordWriter(os.path.join(FLAGS.directory, '../', tfrecord_fname_train))\n",
    "    writer_test = tf.python_io.TFRecordWriter(os.path.join(FLAGS.directory, '../', tfrecord_fname_test))\n",
    "    \n",
    "    disp_step = 400\n",
    "    print('\\nWriting \\\"%s\\\" start' % tfrecord_fname_train)\n",
    "    for itr, idx in enumerate(idxtrain):\n",
    "        label = labels[idx]\n",
    "        imgpath = os.path.join(path, categories[label], imgnames[idx])\n",
    "        image = np.array(Image.open(imgpath))\n",
    "        \n",
    "        height = image.shape[0]\n",
    "        width = image.shape[1]\n",
    "        try:\n",
    "            depth = image.shape[2]\n",
    "        except:\n",
    "            depth = 1\n",
    "        image_str = image.tostring()\n",
    "\n",
    "        example = tf.train.Example(features=tf.train.Features(feature={\n",
    "            'height': _int64_feature(height),\n",
    "            'width': _int64_feature(width),\n",
    "            'depth': _int64_feature(depth),\n",
    "            'image_raw': _bytes_feature(image_str),\n",
    "            'label': _int64_feature(label)\n",
    "        }))\n",
    "        writer_train.write(example.SerializeToString())\n",
    "        \n",
    "        if (itr+1)% disp_step == 0 or (itr+1) == idxtrain.shape[0]:\n",
    "            print('[%3d/%3d] train data has been written' % (itr+1,\n",
    "                                                             idxtrain.shape[0]))\n",
    "    \n",
    "    print('\\nWriting \\\"%s\\\" start' % tfrecord_fname_test)\n",
    "    for itr, idx in enumerate(idxtest):\n",
    "        label = labels[idx]\n",
    "        imgpath = os.path.join(path, categories[label], imgnames[idx])\n",
    "        image = np.array(Image.open(imgpath))\n",
    "        height = image.shape[0]\n",
    "        width = image.shape[1]\n",
    "        try:\n",
    "            depth = image.shape[2]\n",
    "        except:\n",
    "            depth = 1\n",
    "        image_str = image.tostring()\n",
    "\n",
    "        example = tf.train.Example(features=tf.train.Features(feature={\n",
    "            'height': _int64_feature(height),\n",
    "            'width': _int64_feature(width),\n",
    "            'depth': _int64_feature(depth),\n",
    "            'image_raw': _bytes_feature(image_str),\n",
    "            'label': _int64_feature(label)\n",
    "        }))\n",
    "        writer_test.write(example.SerializeToString())\n",
    "        \n",
    "        if (itr+1) % disp_step == 0 or (itr+1) == idxtest.shape[0]:\n",
    "            print('[%3d/%3d] test data has been written' % (itr+1,\n",
    "                                                            idxtest.shape[0]))\n",
    "\n",
    "    writer_train.close()\n",
    "    writer_test.close()\n",
    "    print('Done')              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 categories in /home/chang/notebooks/2017/tf-slim/tmp/data/101_ObjectCategories\n",
      "[  1/101] 435 Faces images are found\n",
      "[  2/101] 435 Faces_easy images are found\n",
      "[  3/101] 200 Leopards images are found\n",
      "[  4/101] 798 Motorbikes images are found\n",
      "[  5/101] 55 accordion images are found\n",
      "[  6/101] 800 airplanes images are found\n",
      "[  7/101] 42 anchor images are found\n",
      "[  8/101] 42 ant images are found\n",
      "[  9/101] 47 barrel images are found\n",
      "[ 10/101] 54 bass images are found\n",
      "[ 11/101] 46 beaver images are found\n",
      "[ 12/101] 33 binocular images are found\n",
      "[ 13/101] 128 bonsai images are found\n",
      "[ 14/101] 98 brain images are found\n",
      "[ 15/101] 43 brontosaurus images are found\n",
      "[ 16/101] 85 buddha images are found\n",
      "[ 17/101] 91 butterfly images are found\n",
      "[ 18/101] 50 camera images are found\n",
      "[ 19/101] 43 cannon images are found\n",
      "[ 20/101] 123 car_side images are found\n",
      "[ 21/101] 47 ceiling_fan images are found\n",
      "[ 22/101] 59 cellphone images are found\n",
      "[ 23/101] 62 chair images are found\n",
      "[ 24/101] 107 chandelier images are found\n",
      "[ 25/101] 47 cougar_body images are found\n",
      "[ 26/101] 69 cougar_face images are found\n",
      "[ 27/101] 73 crab images are found\n",
      "[ 28/101] 70 crayfish images are found\n",
      "[ 29/101] 50 crocodile images are found\n",
      "[ 30/101] 51 crocodile_head images are found\n",
      "[ 31/101] 57 cup images are found\n",
      "[ 32/101] 67 dalmatian images are found\n",
      "[ 33/101] 52 dollar_bill images are found\n",
      "[ 34/101] 65 dolphin images are found\n",
      "[ 35/101] 68 dragonfly images are found\n",
      "[ 36/101] 75 electric_guitar images are found\n",
      "[ 37/101] 64 elephant images are found\n",
      "[ 38/101] 53 emu images are found\n",
      "[ 39/101] 64 euphonium images are found\n",
      "[ 40/101] 85 ewer images are found\n",
      "[ 41/101] 67 ferry images are found\n",
      "[ 42/101] 67 flamingo images are found\n",
      "[ 43/101] 45 flamingo_head images are found\n",
      "[ 44/101] 34 garfield images are found\n",
      "[ 45/101] 34 gerenuk images are found\n",
      "[ 46/101] 51 gramophone images are found\n",
      "[ 47/101] 99 grand_piano images are found\n",
      "[ 48/101] 100 hawksbill images are found\n",
      "[ 49/101] 42 headphone images are found\n",
      "[ 50/101] 54 hedgehog images are found\n",
      "[ 51/101] 88 helicopter images are found\n",
      "[ 52/101] 80 ibis images are found\n",
      "[ 53/101] 31 inline_skate images are found\n",
      "[ 54/101] 64 joshua_tree images are found\n",
      "[ 55/101] 86 kangaroo images are found\n",
      "[ 56/101] 114 ketch images are found\n",
      "[ 57/101] 61 lamp images are found\n",
      "[ 58/101] 81 laptop images are found\n",
      "[ 59/101] 78 llama images are found\n",
      "[ 60/101] 41 lobster images are found\n",
      "[ 61/101] 66 lotus images are found\n",
      "[ 62/101] 43 mandolin images are found\n",
      "[ 63/101] 40 mayfly images are found\n",
      "[ 64/101] 87 menorah images are found\n",
      "[ 65/101] 32 metronome images are found\n",
      "[ 66/101] 76 minaret images are found\n",
      "[ 67/101] 55 nautilus images are found\n",
      "[ 68/101] 35 octopus images are found\n",
      "[ 69/101] 39 okapi images are found\n",
      "[ 70/101] 47 pagoda images are found\n",
      "[ 71/101] 38 panda images are found\n",
      "[ 72/101] 45 pigeon images are found\n",
      "[ 73/101] 53 pizza images are found\n",
      "[ 74/101] 34 platypus images are found\n",
      "[ 75/101] 57 pyramid images are found\n",
      "[ 76/101] 82 revolver images are found\n",
      "[ 77/101] 59 rhino images are found\n",
      "[ 78/101] 49 rooster images are found\n",
      "[ 79/101] 40 saxophone images are found\n",
      "[ 80/101] 63 schooner images are found\n",
      "[ 81/101] 39 scissors images are found\n",
      "[ 82/101] 84 scorpion images are found\n",
      "[ 83/101] 57 sea_horse images are found\n",
      "[ 84/101] 35 snoopy images are found\n",
      "[ 85/101] 64 soccer_ball images are found\n",
      "[ 86/101] 45 stapler images are found\n",
      "[ 87/101] 86 starfish images are found\n",
      "[ 88/101] 59 stegosaurus images are found\n",
      "[ 89/101] 64 stop_sign images are found\n",
      "[ 90/101] 35 strawberry images are found\n",
      "[ 91/101] 85 sunflower images are found\n",
      "[ 92/101] 49 tick images are found\n",
      "[ 93/101] 86 trilobite images are found\n",
      "[ 94/101] 75 umbrella images are found\n",
      "[ 95/101] 239 watch images are found\n",
      "[ 96/101] 37 water_lilly images are found\n",
      "[ 97/101] 59 wheelchair images are found\n",
      "[ 98/101] 34 wild_cat images are found\n",
      "[ 99/101] 56 windsor_chair images are found\n",
      "[100/101] 39 wrench images are found\n",
      "[101/101] 60 yin_yang images are found\n",
      "\n",
      "Writing \"custom_train.tfrecords\" start\n",
      "[400/6073] train data has been written\n",
      "[800/6073] train data has been written\n",
      "[1200/6073] train data has been written\n",
      "[1600/6073] train data has been written\n",
      "[2000/6073] train data has been written\n",
      "[2400/6073] train data has been written\n",
      "[2800/6073] train data has been written\n",
      "[3200/6073] train data has been written\n",
      "[3600/6073] train data has been written\n",
      "[4000/6073] train data has been written\n",
      "[4400/6073] train data has been written\n",
      "[4800/6073] train data has been written\n",
      "[5200/6073] train data has been written\n",
      "[5600/6073] train data has been written\n",
      "[6000/6073] train data has been written\n",
      "[6073/6073] train data has been written\n",
      "\n",
      "Writing \"custom_test.tfrecords\" start\n",
      "[400/2604] test data has been written\n",
      "[800/2604] test data has been written\n",
      "[1200/2604] test data has been written\n",
      "[1600/2604] test data has been written\n",
      "[2000/2604] test data has been written\n",
      "[2400/2604] test data has been written\n",
      "[2604/2604] test data has been written\n",
      "Done\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py:2889: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        '--directory',\n",
    "        type=str,\n",
    "        default='tmp/data/101_ObjectCategories',\n",
    "        help='Directory to read data files and write the converted result'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--trainset_ratio',\n",
    "        type=float,\n",
    "        default=0.7,\n",
    "        help='Ratio of trainset to whole data'\n",
    "    )\n",
    "    FLAGS, unparsed = parser.parse_known_args()\n",
    "    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
